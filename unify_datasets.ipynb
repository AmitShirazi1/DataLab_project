{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00e916bb-2966-484d-9f43-02fade5d48b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "curr_dir = os.getcwd()\n",
    "data_path = os.path.join(curr_dir, \"data/\")\n",
    "questions_data_path = os.path.join(data_path, \"questions_and_answers/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acd27b44-f503-4480-ae67-f56604e1695e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_solution_url(problem_number):\n",
    "    \"\"\"\n",
    "    Determine the GitHub solution file URL based on the problem number.\n",
    "    \"\"\"\n",
    "    base_url = \"https://github.com/fishercoder1534/Leetcode/blob/master/src/main/java/com/fishercoder/solutions/\"\n",
    "    \n",
    "    # Determine the folder\n",
    "    if problem_number < 1000:\n",
    "        folder = \"firstthousand\"\n",
    "    elif problem_number < 2000:\n",
    "        folder = \"secondthousand\"\n",
    "    elif problem_number < 3000:\n",
    "        folder = \"thirdthousand\"\n",
    "    else:\n",
    "        folder = \"fourththousand\"\n",
    "    \n",
    "    # Construct the URL\n",
    "    return f\"{base_url}{folder}/_{problem_number}.java\"\n",
    "\n",
    "\n",
    "def fetch_solution(url):\n",
    "    \"\"\"\n",
    "    Fetch the raw content of the solution from the GitHub file URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert the GitHub URL to the raw content URL\n",
    "        raw_url = url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\")\n",
    "        \n",
    "        # Fetch the solution content\n",
    "        response = requests.get(raw_url)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            # Failed to fetch solution - ignore\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching solution from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_leetcode_solutions():\n",
    "    # Load the LeetCode problems dataset\n",
    "    leetcode_problem_content = pd.read_csv(os.path.join(questions_data_path, \"leetcode_problems_data.csv\")) \\\n",
    "        .drop(columns=[\"title\", \"likes\", \"dislikes\"]) \\\n",
    "        .rename(columns={\"slug\": \"formatted_title\"}) \\\n",
    "        .assign(formatted_title=lambda df: df[\"formatted_title\"].apply(lambda x: x.lower()))  # TODO: Need to remove html tags from Content column\n",
    "    # Original columns: question_id,title,content,difficulty,likes,dislikes,slug.\n",
    "    # New columns: question_id,formatted_title,content,difficulty.\n",
    "\n",
    "    leetcode_problem_meta = pd.read_csv(os.path.join(questions_data_path, \"leetcode_problems_metadata.csv\")) \\\n",
    "        .drop(columns=[\"page_number\", \"is_premium\", \"title\", \"accepted\", \"submission\", \"solution\", \"discussion_count\", \"likes\", \"dislikes\"]) \\\n",
    "        .assign(problem_URL=lambda df: df[\"problem_URL\"].apply(lambda x: x.split(\"/\")[-1])) \\\n",
    "        .rename(columns={\"id\": \"question_id\", \"problem_description\": \"content\", \"problem_URL\": \"formatted_title\"})  # TODO: May need to remove prefix numbers from the Title column.\n",
    "    # Original columns: id,page_number,is_premium,title,problem_description,topic_tags,difficulty,similar_questions,no_similar_questions,acceptance,accepted,submission,solution,discussion_count,likes,dislikes,problem_URL,solution_URL.\n",
    "    # New columns: question_id,content,topic_tags,difficulty,similar_questions,no_similar_questions,acceptance, formatted_title,solution_URL.\n",
    "\n",
    "    leetcode_links = pd.read_csv(os.path.join(questions_data_path, \"leetcode_problems&solutions_links.csv\")) \\\n",
    "        .drop(columns=[\"name\"]) \\\n",
    "        .assign(problem_URL=lambda df: df[\"link\"].apply(lambda x: x.split(\"/\")[-2])) \\\n",
    "        .rename(columns={\"link\": \"formatted_title\", \"solution\": \"solution_URL\"})\n",
    "    # Original columns: name,link,difficulty,solution.\n",
    "    # New columns: formatted_title,difficulty,solution_URL.\n",
    "    \n",
    "    # Merge datasets\n",
    "    leetcode_combined = pd.merge(leetcode_problem_content, leetcode_problem_meta, on=[\"question_id\", \"formatted_title\", \"content\", \"difficulty\"], how=\"outer\")\n",
    "    \n",
    "    # Add a column for the solution\n",
    "    leetcode_combined[\"solution\"] = None\n",
    "    \n",
    "    # Fetch solutions\n",
    "    for index, row in leetcode_combined.iterrows():\n",
    "        problem_id = row[\"question_id\"]\n",
    "        if not pd.isna(problem_id):\n",
    "            solution_url = get_solution_url(int(problem_id))\n",
    "            solution_content = fetch_solution(solution_url)\n",
    "            leetcode_combined.at[index, \"solution\"] = solution_content\n",
    "    \n",
    "    # Save the updated dataset\n",
    "    leetcode_combined.to_csv(os.path.join(questions_data_path, \"leetcode_problems_with_solutions.csv\"), index=False)\n",
    "    print(\"Updated LeetCode dataset saved with solutions included.\")\n",
    "    \n",
    "    return leetcode_combined\n",
    "\n",
    "# Run the function\n",
    "leetcode_with_solutions = process_leetcode_solutions()\n",
    "leetcode_with_solutions.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b580332f-0f44-4220-83e2-4952612ae50a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def load_and_preprocess_datasets():\n",
    "    \"\"\" Load datasets \"\"\"\n",
    "    # LeetCode datasets\n",
    "    leetcode_problem_content = pd.read_csv(\"leetcode_problems_data.csv\")  # Need to remove html tags from Content column\n",
    "    # Columns: question_id,title,content,difficulty,likes,dislikes,slug\n",
    "    leetcode_meta = pd.read_csv(\"leetcode_problems_metadata.csv\")\n",
    "    # Columns: id,page_number,is_premium,title,problem_description,topic_tags,difficulty,similar_questions,no_similar_questions,acceptance,accepted,submission,solution,discussion_count,likes,dislikes,problem_URL,solution_URL\n",
    "    leetcode_links = pd.read_csv(\"leetcode_problems&solutions_links.csv\")\n",
    "    # Columns: name,link,difficulty,solution\n",
    "    \n",
    "    # Open-ended question datasets\n",
    "    data_science_questions = pd.read_csv(\"open_questions_data_science.csv\")\n",
    "    general_questions = pd.read_csv(\"general_open_questions.csv\")\n",
    "    \n",
    "    # Job description datasets\n",
    "    job_descriptions = pd.read_csv(\"job_descriptions_and_skills.csv\")\n",
    "    linkedin_jobs = pd.read_csv(\"linkedin_hightech_jobs.csv\")\n",
    "    indeed_jobs = pd.read_csv(\"indeed_jobs.csv\")\n",
    "    glassdoor_jobs = pd.read_csv(\"glassdoor_data_jobs_and_company_info.csv\")\n",
    "    linkedin_data_jobs = pd.read_csv(\"linkedin_data_jobs.csv\")\n",
    "    \n",
    "    \"\"\" Preprocess LeetCode datasets \"\"\"\n",
    "    leetcode_combined = pd.merge(leetcode_data, leetcode_meta, on=\"question_id\", how=\"left\")\n",
    "    leetcode_combined = leetcode_combined[[\"question_id\", \"title\", \"content\", \"difficulty\", \"topic\"]]\n",
    "    leetcode_combined[\"category\"] = \"Coding\"\n",
    "    leetcode_combined[\"skills\"] = leetcode_combined[\"topic\"]\n",
    "    leetcode_combined[\"source\"] = \"LeetCode\"\n",
    "    \n",
    "    # Step 3: Preprocess open-ended questions\n",
    "    data_science_questions[\"category\"] = \"Data Science\"\n",
    "    data_science_questions[\"skills\"] = \"Data Science\"\n",
    "    data_science_questions[\"source\"] = \"OpenQuestions_DS\"\n",
    "    \n",
    "    general_questions[\"category\"] = \"General\"\n",
    "    general_questions[\"skills\"] = \"General Skills\"\n",
    "    general_questions[\"source\"] = \"OpenQuestions_General\"\n",
    "    \n",
    "    # Step 4: Combine into a unified database\n",
    "    # Unify columns into the common schema\n",
    "    unified_schema_columns = [\"question id\", \"title\", \"content\", \"difficulty\", \"category\", \"skills\", \"source\"]\n",
    "    leetcode_final = leetcode_combined.rename(columns={\n",
    "        \"question id\": \"question id\",\n",
    "        \"question title\": \"title\",\n",
    "        \"content\": \"content\",\n",
    "        \"difficulty\": \"difficulty\",\n",
    "        \"topic\": \"skills\"\n",
    "    })[unified_schema_columns]\n",
    "    \n",
    "    data_science_final = data_science_questions.rename(columns={\n",
    "        \"Question\": \"content\"\n",
    "    })[[\"content\", \"category\", \"skills\", \"source\"]]\n",
    "    data_science_final[\"question id\"] = None\n",
    "    data_science_final[\"title\"] = None\n",
    "    data_science_final[\"difficulty\"] = None\n",
    "    \n",
    "    general_final = general_questions.rename(columns={\n",
    "        \"Question\": \"content\"\n",
    "    })[[\"content\", \"category\", \"skills\", \"source\"]]\n",
    "    general_final[\"question id\"] = None\n",
    "    general_final[\"title\"] = None\n",
    "    general_final[\"difficulty\"] = None\n",
    "    \n",
    "    # Step 5: Concatenate all into one database\n",
    "    unified_db = pd.concat([leetcode_final, data_science_final, general_final], ignore_index=True)\n",
    "    \n",
    "    # Save the unified database\n",
    "    unified_db.to_csv(\"unified_questions_database.csv\", index=False)\n",
    "    print(\"Unified database created and saved as 'unified_questions_database.csv'\")\n",
    "    \n",
    "    return unified_db\n",
    "\n",
    "unified_database = load_and_preprocess_datasets()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "unify_datasets",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c6629c4-2385-43b1-b94b-d4b8f046d49a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split\n",
    "from consts import DATA_PATH, QUESTIONS_PATH, open_csv_file\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"JobQuestionMatching\").getOrCreate()\n",
    "\n",
    "# Load datasets into Spark DataFrames\n",
    "job_postings = open_csv_file(spark, DATA_PATH, \"train_jobs_data.csv\")\n",
    "job_postings = job_postings.fillna({'skills': ''})\n",
    "code_questions = open_csv_file(spark, QUESTIONS_PATH, \"all_code_questions_with_topics.csv\")\n",
    "open_questions = open_csv_file(spark, QUESTIONS_PATH, \"all_open_questions_with_topics.csv\")\n",
    "print(\"num_rows:\", job_postings.count(), code_questions.count(), open_questions.count())\n",
    "\n",
    "# Explode the skills and topics columns\n",
    "job_postings_exploded = job_postings.withColumn(\"skill\", explode(split(\"skills\", \",\")))\n",
    "code_questions_exploded = code_questions.withColumn(\"topic\", explode(split(\"topics\", \",\")))\n",
    "open_questions_exploded = open_questions.withColumn(\"topic\", explode(split(\"topics\", \",\")))\n",
    "\n",
    "# Cartesian product between job postings and questions\n",
    "cartesian_code = job_postings_exploded.crossJoin(code_questions_exploded)\n",
    "cartesian_open = job_postings_exploded.crossJoin(open_questions_exploded)\n",
    "print(\"num_rows:\", cartesian_code.count(), cartesian_open.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33bc528c-3638-437f-8ad3-9d425a4b04f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from consts import PROJECT_PATH\n",
    "\n",
    "display(cartesian_code)\n",
    "display(cartesian_open)\n",
    "\n",
    "# checkpoints_path = \"dbfs:/tmp/spark-checkpoints/\"\n",
    "# spark.sparkContext.setCheckpointDir(checkpoints_path)\n",
    "# cartesian_code = cartesian_code.checkpoint()\n",
    "# cartesian_open = cartesian_open.checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ab7ffb4-19bf-423c-91dc-da67a4f57f12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4168f5e-68fa-408a-a586-50538153f820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, udf, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, DoubleType\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the model globally\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# UDF to generate embeddings\n",
    "@udf(ArrayType(FloatType()))\n",
    "def generate_embedding(text):\n",
    "    return model.encode(text).tolist()\n",
    "\n",
    "# UDF to calculate cosine similarity\n",
    "@udf(DoubleType())\n",
    "def calculate_similarity(embedding1, embedding2):\n",
    "    return float(cosine_similarity([embedding1], [embedding2])[0][0])\n",
    "\n",
    "# Extract unique skills and topics\n",
    "unique_skills = job_postings_exploded.select(\"skill\").distinct()\n",
    "unique_topics_code = code_questions_exploded.select(\"topic\").distinct()\n",
    "unique_topics_open = open_questions_exploded.select(\"topic\").distinct()\n",
    "\n",
    "# # Cartesian product of unique skills and topics\n",
    "# unique_pairs_code = unique_skills.crossJoin(unique_topics_code)\n",
    "# unique_pairs_open = unique_skills.crossJoin(unique_topics_open)\n",
    "\n",
    "# # Generate embeddings for skills and topics\n",
    "# unique_pairs_code = unique_pairs_code.withColumn(\"skill_embedding\", generate_embedding(col(\"skill\")))\n",
    "# unique_pairs_open = unique_pairs_open.withColumn(\"skill_embedding\", generate_embedding(col(\"skill\")))\n",
    "# unique_pairs_code = unique_pairs_code.withColumn(\"topic_embedding\", generate_embedding(col(\"topic\")))\n",
    "# unique_pairs_open = unique_pairs_open.withColumn(\"topic_embedding\", generate_embedding(col(\"topic\")))\n",
    "\n",
    "# # Compute similarity for unique pairs\n",
    "# unique_pairs_code = unique_pairs_code.withColumn(\n",
    "#     \"similarity\", calculate_similarity(col(\"skill_embedding\"), col(\"topic_embedding\"))\n",
    "# )\n",
    "# unique_pairs_open = unique_pairs_open.withColumn(\n",
    "#     \"similarity\", calculate_similarity(col(\"skill_embedding\"), col(\"topic_embedding\"))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c4d84e6-2d9b-4f95-9cad-8854e32fede2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "With pandas"
    }
   },
   "outputs": [],
   "source": [
    "unique_skills_df = unique_skills.toPandas()\n",
    "unique_topics_code_df = unique_topics_code.toPandas()\n",
    "unique_topics_open_df = unique_topics_open.toPandas()\n",
    "\n",
    "unique_skills_df[\"embedding\"] = unique_skills_df[\"skill\"].apply(model.encode)\n",
    "unique_topics_code_df[\"embedding\"] = unique_topics_code_df[\"topic\"].apply(model.encode)\n",
    "unique_topics_open_df[\"embedding\"] = unique_topics_open_df[\"topic\"].apply(model.encode)\n",
    "\n",
    "unique_pairs_code_df = unique_skills_df.merge(unique_topics_code_df, how=\"cross\")  # Cartesian product\n",
    "unique_pairs_open_df = unique_skills_df.merge(unique_topics_open_df, how=\"cross\")\n",
    "\n",
    "unique_pairs_code_df[\"similarity\"] = unique_pairs_code_df.apply(\n",
    "    lambda row: cosine_similarity([row[\"embedding_x\"]], [row[\"embedding_y\"]])[0][0], axis=1\n",
    ")\n",
    "unique_pairs_open_df[\"similarity\"] = unique_pairs_open_df.apply(\n",
    "    lambda row: cosine_similarity([row[\"embedding_x\"]], [row[\"embedding_y\"]])[0][0], axis=1\n",
    ")\n",
    "\n",
    "unique_pairs_code_df.to_csv(\"unique_pairs_with_similarity_code.csv\", index=False)\n",
    "unique_pairs_open_df.to_csv(\"unique_pairs_with_similarity_open.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ee16344-2e04-459f-b11c-acbe80281d0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(unique_pairs_code_df)\n",
    "display(unique_pairs_open_df)\n",
    "\n",
    "unique_pairs_code = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42375a8d-25d1-4166-b339-c76408d7f9f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_pairs_code.checkpoint()\n",
    "unique_pairs_open.checkpoint()\n",
    "\n",
    "unique_pairs_code.display()\n",
    "unique_pairs_open.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c932be62-2bff-4e34-bf6f-be15ea26791a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Join similarity back to Cartesian product\n",
    "cartesian_code_with_similarity = cartesian_code.join(\n",
    "    broadcast(unique_pairs_code.select(\"skill\", \"topic\", \"similarity\")),\n",
    "    on=[\"skill\", \"topic\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "cartesian_open_with_similarity = cartesian_open.join(\n",
    "    broadcast(unique_pairs_open.select(\"skill\", \"topic\", \"similarity\")),\n",
    "    on=[\"skill\", \"topic\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Aggregate similarity scores for each job-question pair\n",
    "columns_to_group_by = [col for col in cartesian_code.columns if col not in [\"skill\", \"topic\"]]\n",
    "aggregated_code_scores = cartesian_code_with_similarity.groupBy(*columns_to_group_by).agg(\n",
    "    {\"similarity\": \"avg\"}\n",
    ")\n",
    "\n",
    "columns_to_group_by = [col for col in cartesian_open.columns if col not in [\"skill\", \"topic\"]]\n",
    "aggregated_open_scores = cartesian_open_with_similarity.groupBy(*columns_to_group_by).agg(\n",
    "    {\"similarity\": \"avg\"}\n",
    ")\n",
    "\n",
    "aggregated_code_scores.checkpoint()\n",
    "aggregated_open_scores.checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "128c2c73-3688-46b9-b83f-b8aceec5a470",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aggregated_code_scores.display()\n",
    "aggregated_open_scores.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "select_interview_questions_copy",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
